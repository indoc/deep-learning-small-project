{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what was updated:\n",
    "## remove F.log_softmax(x, dim = 1) in Net\n",
    "## changed optimised from SGD to Adam\n",
    "### ok thanks - hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lung_dataset import Lung_Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# A simple mode\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=2):  # TODO: define other parameters here\n",
    "        super(Net, self).__init__()\n",
    "        # Conv2D: 1 input channel, 8 output channels, 3 by 3 kernel, stride of 2.\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3, 1)\n",
    "        self.conv1_ = nn.Conv2d(2, 2, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(2)\n",
    "        self.conv2 = nn.Conv2d(2, 4, 3, 1)\n",
    "        self.conv2_ = nn.Conv2d(4, 4, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(4)\n",
    "        self.conv3 = nn.Conv2d(4, 6, 3, 1)\n",
    "        self.conv3_ = nn.Conv2d(6, 6, 3, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(6)\n",
    "        self.conv4 = nn.Conv2d(6, 8, 3, 1)\n",
    "        self.conv4_ = nn.Conv2d(8, 8, 3, 1)\n",
    "        self.bn4 = nn.BatchNorm2d(8)\n",
    "        self.mp = nn.MaxPool2d(3, stride=2)\n",
    "        self.fc1 = nn.Linear(128, 16)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.fc2 = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv1_(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv3_(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.mp(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv4_(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.mp(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x\n",
    "        return output\n",
    "\n",
    "    def count_parameters(self):\n",
    "        # https://stackoverflow.com/a/62764464/5894029\n",
    "        return sum(dict((p.data_ptr(), p.numel()) for p in self.parameters()).values())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, testloader, model, optimizer, num_epochs=2):\n",
    "    print(\"Training {} parameters\".format(net.count_parameters()))\n",
    "    model = model.to(device)\n",
    "    test_accuracies = []\n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        model.train()\n",
    "        train_running_loss = 0.0\n",
    "        train_total = 0\n",
    "        train_correct = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum()\n",
    "            train_running_loss += loss.item()\n",
    "            train_total += labels.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        \n",
    "        test_running_loss = 0.0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            test_correct += (predicted == labels).sum()\n",
    "            test_running_loss += loss.item()\n",
    "            test_total += labels.size(0)\n",
    "            \n",
    "        test_accuracy = test_correct / test_total\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        print('[epoch {}] training loss/acc: {:.3f} {:.3f}, testing loss/acc: {:.3f} {:.3f}'.format(\n",
    "            epoch + 1, \n",
    "            train_running_loss / train_total, train_correct / train_total, \n",
    "            test_running_loss / test_total, test_accuracy))\n",
    "\n",
    "    print('Finished Training, average test accuracy of last 10 epochs: {:.3f}'.format(sum(test_accuracies[-10:])/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_val = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches 326, Test batches 39\n",
      "Training 4013 parameters\n",
      "[epoch 1] training loss/acc: 0.043 0.686, testing loss/acc: 0.051 0.694\n",
      "[epoch 2] training loss/acc: 0.037 0.724, testing loss/acc: 0.068 0.659\n",
      "[epoch 3] training loss/acc: 0.035 0.756, testing loss/acc: 0.049 0.740\n",
      "[epoch 4] training loss/acc: 0.033 0.763, testing loss/acc: 0.056 0.680\n",
      "[epoch 5] training loss/acc: 0.032 0.768, testing loss/acc: 0.060 0.649\n",
      "[epoch 6] training loss/acc: 0.031 0.784, testing loss/acc: 0.060 0.680\n",
      "[epoch 7] training loss/acc: 0.031 0.775, testing loss/acc: 0.072 0.665\n",
      "[epoch 8] training loss/acc: 0.030 0.786, testing loss/acc: 0.058 0.702\n",
      "[epoch 9] training loss/acc: 0.030 0.789, testing loss/acc: 0.075 0.652\n",
      "[epoch 10] training loss/acc: 0.029 0.794, testing loss/acc: 0.069 0.668\n",
      "[epoch 11] training loss/acc: 0.029 0.791, testing loss/acc: 0.055 0.704\n",
      "[epoch 12] training loss/acc: 0.029 0.800, testing loss/acc: 0.059 0.720\n",
      "[epoch 13] training loss/acc: 0.028 0.799, testing loss/acc: 0.050 0.750\n",
      "[epoch 14] training loss/acc: 0.028 0.805, testing loss/acc: 0.063 0.699\n",
      "[epoch 15] training loss/acc: 0.028 0.798, testing loss/acc: 0.079 0.652\n",
      "[epoch 16] training loss/acc: 0.028 0.807, testing loss/acc: 0.064 0.691\n",
      "[epoch 17] training loss/acc: 0.028 0.804, testing loss/acc: 0.067 0.714\n",
      "[epoch 18] training loss/acc: 0.027 0.808, testing loss/acc: 0.059 0.724\n",
      "[epoch 19] training loss/acc: 0.027 0.809, testing loss/acc: 0.060 0.727\n",
      "[epoch 20] training loss/acc: 0.027 0.808, testing loss/acc: 0.063 0.712\n",
      "Finished Training, average test accuracy of last 10 epochs: 0.709\n"
     ]
    }
   ],
   "source": [
    "net = Net(num_classes=3)\n",
    "\n",
    "ld = Lung_Dataset(\"train\", \"normal/non-covid/covid\")\n",
    "trainloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "ld = Lung_Dataset(\"test\", \"normal/non-covid/covid\")\n",
    "testloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Train batches {}, Test batches {}\".format(len(trainloader), len(testloader)))\n",
    "train(trainloader, testloader, net, optimizer)\n",
    "\n",
    "# TODO: Visualisation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal vs Infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches 326, Test batches 39\n",
      "Training 4013 parameters\n",
      "[epoch 1] training loss/acc: 0.016 0.893, testing loss/acc: 0.029 0.803\n",
      "[epoch 2] training loss/acc: 0.010 0.939, testing loss/acc: 0.041 0.764\n",
      "[epoch 3] training loss/acc: 0.009 0.945, testing loss/acc: 0.050 0.725\n",
      "[epoch 4] training loss/acc: 0.007 0.958, testing loss/acc: 0.046 0.758\n",
      "[epoch 5] training loss/acc: 0.007 0.958, testing loss/acc: 0.052 0.733\n",
      "[epoch 6] training loss/acc: 0.006 0.963, testing loss/acc: 0.033 0.833\n",
      "[epoch 7] training loss/acc: 0.006 0.966, testing loss/acc: 0.035 0.815\n",
      "[epoch 8] training loss/acc: 0.006 0.965, testing loss/acc: 0.054 0.759\n",
      "[epoch 9] training loss/acc: 0.005 0.970, testing loss/acc: 0.044 0.808\n",
      "[epoch 10] training loss/acc: 0.005 0.969, testing loss/acc: 0.059 0.764\n",
      "[epoch 11] training loss/acc: 0.005 0.970, testing loss/acc: 0.038 0.816\n",
      "[epoch 12] training loss/acc: 0.005 0.972, testing loss/acc: 0.044 0.816\n",
      "[epoch 13] training loss/acc: 0.004 0.975, testing loss/acc: 0.045 0.805\n",
      "[epoch 14] training loss/acc: 0.004 0.975, testing loss/acc: 0.048 0.795\n",
      "[epoch 15] training loss/acc: 0.004 0.976, testing loss/acc: 0.048 0.818\n",
      "[epoch 16] training loss/acc: 0.004 0.975, testing loss/acc: 0.061 0.743\n",
      "[epoch 17] training loss/acc: 0.004 0.978, testing loss/acc: 0.067 0.754\n",
      "[epoch 18] training loss/acc: 0.004 0.978, testing loss/acc: 0.065 0.763\n",
      "[epoch 19] training loss/acc: 0.004 0.977, testing loss/acc: 0.057 0.767\n",
      "[epoch 20] training loss/acc: 0.004 0.974, testing loss/acc: 0.047 0.807\n",
      "Finished Training, average test accuracy of last 10 epochs: 0.788\n"
     ]
    }
   ],
   "source": [
    "first_net = Net(num_classes=2)\n",
    "\n",
    "ld = Lung_Dataset(\"train\", \"normal/infected\")\n",
    "trainloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "ld = Lung_Dataset(\"test\", \"normal/infected\")\n",
    "testloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "optimizer = optim.Adam(first_net.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Train batches {}, Test batches {}\".format(len(trainloader), len(testloader)))\n",
    "train(trainloader, testloader, first_net, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infected vs Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches 243, Test batches 24\n",
      "Training 4013 parameters\n",
      "[epoch 1] training loss/acc: 0.039 0.681, testing loss/acc: 0.030 0.793\n",
      "[epoch 2] training loss/acc: 0.036 0.721, testing loss/acc: 0.027 0.864\n",
      "[epoch 3] training loss/acc: 0.035 0.731, testing loss/acc: 0.027 0.816\n",
      "[epoch 4] training loss/acc: 0.034 0.736, testing loss/acc: 0.029 0.827\n",
      "[epoch 5] training loss/acc: 0.033 0.745, testing loss/acc: 0.026 0.827\n",
      "[epoch 6] training loss/acc: 0.034 0.742, testing loss/acc: 0.025 0.840\n",
      "[epoch 7] training loss/acc: 0.033 0.746, testing loss/acc: 0.025 0.832\n",
      "[epoch 8] training loss/acc: 0.033 0.748, testing loss/acc: 0.023 0.871\n",
      "[epoch 9] training loss/acc: 0.032 0.751, testing loss/acc: 0.027 0.790\n",
      "[epoch 10] training loss/acc: 0.032 0.758, testing loss/acc: 0.022 0.911\n",
      "[epoch 11] training loss/acc: 0.032 0.765, testing loss/acc: 0.024 0.892\n",
      "[epoch 12] training loss/acc: 0.031 0.765, testing loss/acc: 0.022 0.874\n",
      "[epoch 13] training loss/acc: 0.031 0.759, testing loss/acc: 0.022 0.887\n",
      "[epoch 14] training loss/acc: 0.031 0.767, testing loss/acc: 0.024 0.887\n",
      "[epoch 15] training loss/acc: 0.030 0.770, testing loss/acc: 0.024 0.840\n",
      "[epoch 16] training loss/acc: 0.030 0.774, testing loss/acc: 0.022 0.866\n",
      "[epoch 17] training loss/acc: 0.030 0.772, testing loss/acc: 0.022 0.885\n",
      "[epoch 18] training loss/acc: 0.030 0.780, testing loss/acc: 0.023 0.864\n",
      "[epoch 19] training loss/acc: 0.030 0.774, testing loss/acc: 0.024 0.848\n",
      "[epoch 20] training loss/acc: 0.030 0.773, testing loss/acc: 0.027 0.798\n",
      "Finished Training, average test accuracy of last 10 epochs: 0.864\n"
     ]
    }
   ],
   "source": [
    "second_net = Net(num_classes=2)\n",
    "\n",
    "ld = Lung_Dataset(\"train\", \"covid/non-covid\")\n",
    "trainloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "ld = Lung_Dataset(\"test\", \"covid/non-covid\")\n",
    "testloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "optimizer = optim.Adam(second_net.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Train batches {}, Test batches {}\".format(len(trainloader), len(testloader)))\n",
    "train(trainloader, testloader, second_net, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two stage classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def two_stage_testing(testloader, first_model, second_model):\n",
    "        first_model.eval()\n",
    "        second_model.eval()\n",
    "        first_model = first_model.to(device)\n",
    "        second_model = second_model.to(device)\n",
    "        \n",
    "        first_stage_labels = []\n",
    "        second_stage_labels = []\n",
    "        actual_labels = []\n",
    "        \n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = first_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            first_stage_labels.extend(predicted)\n",
    "\n",
    "            outputs = second_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            second_stage_labels.extend(predicted)\n",
    "            \n",
    "            actual_labels.extend(labels)\n",
    "            \n",
    "        \n",
    "        predicted_labels = [0 if not first_label else 2 if not second_label else 1 for\n",
    "                            first_label, second_label in zip(first_stage_labels, second_stage_labels)]\n",
    "\n",
    "        first_stage_labels = [x.item() for x in first_stage_labels]\n",
    "        second_stage_labels = [x.item() for x in second_stage_labels]\n",
    "        actual_labels = [x.item() for x in actual_labels]\n",
    "        print(first_stage_labels[:10])\n",
    "        print(second_stage_labels[:10])\n",
    "        print(predicted_labels[:10])\n",
    "        print(actual_labels[:10])\n",
    "        \n",
    "        print(collections.Counter(predicted_labels))\n",
    "        print(collections.Counter(actual_labels))\n",
    "        \n",
    "        accuracy = sum(actual == predicted for actual, predicted in zip(actual_labels, predicted_labels))/len(actual_labels)\n",
    "        print(\"accuracy {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 2, 0, 0, 2, 2, 2, 2, 2, 2]\n",
      "[0, 0, 1, 0, 0, 2, 0, 2, 1, 2]\n",
      "Counter({2: 290, 1: 204, 0: 121})\n",
      "Counter({1: 242, 0: 234, 2: 139})\n",
      "accuracy 0.685\n"
     ]
    }
   ],
   "source": [
    "ld = Lung_Dataset(\"test\", \"normal/non-covid/covid\")\n",
    "testloader = DataLoader(ld, batch_size = bs_val, shuffle = True)\n",
    "\n",
    "two_stage_testing(testloader, first_net, second_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook two-binary-classifier.ipynb to script\n",
      "[NbConvertApp] Writing 7959 bytes to two-binary-classifier.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    get_ipython().system('jupyter nbconvert --to script two-binary-classifier.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
